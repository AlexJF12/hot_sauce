{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HEATHOTSAUCE.COM SCRAPE\n",
    "\n",
    "https://heathotsauce.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 <Response [200]>\n",
      "2 <Response [200]>\n",
      "3 <Response [200]>\n",
      "4 <Response [200]>\n",
      "5 <Response [200]>\n",
      "6 <Response [200]>\n",
      "7 <Response [200]>\n",
      "8 <Response [200]>\n",
      "9 <Response [200]>\n",
      "10 <Response [200]>\n",
      "11 <Response [200]>\n",
      "12 <Response [200]>\n",
      "13 <Response [200]>\n"
     ]
    }
   ],
   "source": [
    "# scrape all 13 pages to get names and urls\n",
    "\n",
    "names = []\n",
    "urls = []\n",
    "\n",
    "# go to each page (print progress)\n",
    "for i in range(1, 14):\n",
    "    url = 'https://heathotsauce.com/collections/all?page=' + str(i)\n",
    "    page = requests.get(url)\n",
    "    print i, page\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "    \n",
    "    #in each page, scrape the names\n",
    "    for j in soup.findAll('span', class_='title product-name-custom'):\n",
    "        names.append(j.get_text())\n",
    "    for k in soup.findAll(itemprop = 'url'):\n",
    "        urls.append(k.get('href'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#combine names and urls into a df\n",
    "names_urls = pd.DataFrame({'names':names, 'urls':urls})\n",
    "\n",
    "# add url to start of urls\n",
    "names_urls['urls'] = names_urls['urls'].apply(lambda x: 'https://heathotsauce.com' + str(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 <Response [200]>\n",
      "1 <Response [200]>\n",
      "2 <Response [200]>\n",
      "3 <Response [200]>\n",
      "4 <Response [200]>\n",
      "5 <Response [200]>\n",
      "6 <Response [200]>\n",
      "7 <Response [200]>\n",
      "8 <Response [200]>\n",
      "9 <Response [200]>\n",
      "10 <Response [200]>\n",
      "11 <Response [200]>\n",
      "12 <Response [200]>\n",
      "13 <Response [200]>\n",
      "14 <Response [200]>\n",
      "15 <Response [200]>\n",
      "16 <Response [200]>\n",
      "17 <Response [200]>\n",
      "18 <Response [200]>\n",
      "19 <Response [200]>\n",
      "20 <Response [200]>\n",
      "21 <Response [200]>\n",
      "22 <Response [200]>\n",
      "23 <Response [200]>\n",
      "24 <Response [200]>\n",
      "25 <Response [200]>\n",
      "26 <Response [200]>\n",
      "27 <Response [200]>\n",
      "28 <Response [200]>\n",
      "29 <Response [200]>\n",
      "30 <Response [200]>\n",
      "31 <Response [200]>\n",
      "32 <Response [200]>\n",
      "33 <Response [200]>\n",
      "34 <Response [200]>\n",
      "35 <Response [200]>\n",
      "36 <Response [200]>\n",
      "37 <Response [200]>\n",
      "38 <Response [200]>\n",
      "39 <Response [200]>\n",
      "40 <Response [200]>\n",
      "41 <Response [200]>\n",
      "42 <Response [200]>\n",
      "43 <Response [200]>\n",
      "44 <Response [200]>\n",
      "45 <Response [200]>\n",
      "46 <Response [200]>\n",
      "47 <Response [200]>\n",
      "48 <Response [200]>\n",
      "49 <Response [200]>\n",
      "50 <Response [200]>\n",
      "51 <Response [200]>\n",
      "52 <Response [200]>\n",
      "53 <Response [200]>\n",
      "54 <Response [200]>\n",
      "55 <Response [200]>\n",
      "56 <Response [200]>\n",
      "57 <Response [200]>\n",
      "58 <Response [200]>\n",
      "59 <Response [200]>\n",
      "60 <Response [200]>\n",
      "61 <Response [200]>\n",
      "62 <Response [200]>\n",
      "63 <Response [200]>\n",
      "64 <Response [200]>\n",
      "65 <Response [200]>\n",
      "66 <Response [200]>\n",
      "67 <Response [200]>\n",
      "68 <Response [200]>\n",
      "69 <Response [200]>\n",
      "70 <Response [200]>\n",
      "71 <Response [200]>\n",
      "72 <Response [200]>\n",
      "73 <Response [200]>\n",
      "74 <Response [200]>\n",
      "75 <Response [200]>\n",
      "76 <Response [200]>\n",
      "77 <Response [200]>\n",
      "78 <Response [200]>\n",
      "79 <Response [200]>\n",
      "80 <Response [200]>\n",
      "81 <Response [200]>\n",
      "82 <Response [200]>\n",
      "83 <Response [200]>\n",
      "84 <Response [200]>\n",
      "85 <Response [200]>\n",
      "86 <Response [200]>\n",
      "87 <Response [200]>\n",
      "88 <Response [200]>\n",
      "89 <Response [200]>\n",
      "90 <Response [200]>\n",
      "91 <Response [200]>\n",
      "92 <Response [200]>\n",
      "93 <Response [200]>\n",
      "94 <Response [200]>\n",
      "95 <Response [200]>\n",
      "96 <Response [200]>\n",
      "97 <Response [200]>\n",
      "98 <Response [200]>\n",
      "99 <Response [200]>\n",
      "100 <Response [200]>\n",
      "101 <Response [200]>\n",
      "102 <Response [200]>\n",
      "103 <Response [200]>\n",
      "104 <Response [200]>\n",
      "105 <Response [200]>\n",
      "106 <Response [200]>\n",
      "107 <Response [200]>\n",
      "108 <Response [200]>\n",
      "109 <Response [200]>\n",
      "110 <Response [200]>\n",
      "111 <Response [200]>\n",
      "112 <Response [200]>\n",
      "113 <Response [200]>\n",
      "114 <Response [200]>\n",
      "115 <Response [200]>\n",
      "116 <Response [200]>\n",
      "117 <Response [200]>\n",
      "118 <Response [200]>\n",
      "119 <Response [200]>\n",
      "120 <Response [200]>\n",
      "121 <Response [200]>\n",
      "122 <Response [200]>\n",
      "123 <Response [200]>\n",
      "124 <Response [200]>\n",
      "125 <Response [200]>\n",
      "126 <Response [200]>\n",
      "127 <Response [200]>\n",
      "128 <Response [200]>\n",
      "129 <Response [200]>\n",
      "130 <Response [200]>\n",
      "131 <Response [200]>\n",
      "132 <Response [200]>\n",
      "133 <Response [200]>\n",
      "134 <Response [200]>\n",
      "135 <Response [200]>\n",
      "136 <Response [200]>\n",
      "137 <Response [200]>\n",
      "138 <Response [200]>\n",
      "139 <Response [200]>\n",
      "140 <Response [200]>\n",
      "141 <Response [200]>\n",
      "142 <Response [200]>\n",
      "143 <Response [200]>\n",
      "144 <Response [200]>\n",
      "145 <Response [200]>\n",
      "146 <Response [200]>\n",
      "147 <Response [200]>\n",
      "148 <Response [200]>\n",
      "149 <Response [200]>\n",
      "150 <Response [200]>\n",
      "151 <Response [200]>\n",
      "152 <Response [200]>\n",
      "153 <Response [200]>\n",
      "154 <Response [200]>\n",
      "155 <Response [200]>\n",
      "156 <Response [200]>\n",
      "157 <Response [200]>\n",
      "158 <Response [200]>\n",
      "159 <Response [200]>\n",
      "160 <Response [200]>\n",
      "161 <Response [200]>\n",
      "162 <Response [200]>\n",
      "163 <Response [200]>\n",
      "164 <Response [200]>\n",
      "165 <Response [200]>\n",
      "166 <Response [200]>\n",
      "167 <Response [200]>\n",
      "168 <Response [200]>\n",
      "169 <Response [200]>\n",
      "170 <Response [200]>\n",
      "171 <Response [200]>\n",
      "172 <Response [200]>\n",
      "173 <Response [200]>\n",
      "174 <Response [200]>\n",
      "175 <Response [200]>\n",
      "176 <Response [200]>\n",
      "177 <Response [200]>\n",
      "178 <Response [200]>\n",
      "179 <Response [200]>\n",
      "180 <Response [200]>\n",
      "181 <Response [200]>\n",
      "182 <Response [200]>\n",
      "183 <Response [200]>\n",
      "184 <Response [200]>\n",
      "185 <Response [200]>\n",
      "186 <Response [200]>\n",
      "187 <Response [200]>\n",
      "188 <Response [200]>\n",
      "189 <Response [200]>\n",
      "190 <Response [200]>\n",
      "191 <Response [200]>\n",
      "192 <Response [200]>\n",
      "193 <Response [200]>\n",
      "194 <Response [200]>\n",
      "195 <Response [200]>\n",
      "196 <Response [200]>\n",
      "197 <Response [200]>\n",
      "198 <Response [200]>\n",
      "199 <Response [200]>\n",
      "200 <Response [200]>\n",
      "201 <Response [200]>\n",
      "202 <Response [200]>\n",
      "203 <Response [200]>\n",
      "204 <Response [200]>\n",
      "205 <Response [200]>\n",
      "206 <Response [200]>\n",
      "207 <Response [200]>\n"
     ]
    }
   ],
   "source": [
    "## Go to each unique url, grab name, price, manufacturer, description\n",
    "\n",
    "## NOTE: I requested too many timesand was timed out. \n",
    "## Do this in batches, save as different df, then concat together\n",
    "\n",
    "name = []\n",
    "mfc = []\n",
    "price = []\n",
    "desc = []\n",
    "urls = []\n",
    "\n",
    "for n, url in enumerate(names_urls['urls'][400:]):\n",
    "    page = requests.get(url)\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "    \n",
    "#     name\n",
    "    try:\n",
    "        name.append(soup.find('h1', class_='product_name').get_text())\n",
    "    except:\n",
    "        name.append('')\n",
    "#     manufacturer\n",
    "    try:\n",
    "        mfc.append(soup.find('p', class_='vendor').get_text())\n",
    "    except:\n",
    "        mfc.append('')\n",
    "#     price\n",
    "    try:\n",
    "        price.append(soup.find('span', class_='money').get_text())\n",
    "    except:\n",
    "        price.append('')\n",
    "#     description\n",
    "    try:\n",
    "        desc.append(soup.find('div', class_='description').get_text())\n",
    "    except:\n",
    "        desc.append('')\n",
    "#     url\n",
    "    try:\n",
    "        urls.append(url)\n",
    "    except:\n",
    "        urls.append('')\n",
    "    \n",
    "#     print progress, if response != 200, stop kernel. you have been timed out\n",
    "    print n, page\n",
    "\n",
    "df3 = pd.DataFrame({'names':name,\n",
    "                   'mfc':mfc,\n",
    "                   'price':price,\n",
    "                   'desc':desc,\n",
    "                   'url':urls})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# combine all df batches. strip manufacturers of \\n\n",
    "full_df = pd.concat([df1, df2, df3])\n",
    "full_df['mfc'] = full_df['mfc'].apply(lambda x: x.strip())\n",
    "\n",
    "# remove gift sets and empty rows\n",
    "full_df = full_df[full_df['mfc'] != 'Gift Set']\n",
    "full_df = full_df[full_df['desc'] != '']\n",
    "full_df.reset_index(inplace=True, drop=True)\n",
    "\n",
    "# save df as csv\n",
    "full_df.to_csv('hot_sauces.csv', encoding='utf-8', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
